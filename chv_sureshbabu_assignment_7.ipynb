{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vSureshbabuchitturi/Data-Science-NLP-/blob/main/chv_sureshbabu_assignment_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9691c16c",
      "metadata": {
        "id": "9691c16c"
      },
      "source": [
        "# Assignment 7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f07eee",
      "metadata": {
        "id": "92f07eee"
      },
      "source": [
        "# Please save your file with your name.ipynb and share this Jupter notebook with solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234ec53d",
      "metadata": {
        "id": "234ec53d"
      },
      "outputs": [],
      "source": [
        "# Question 1\n",
        "# What are the disadvantages of using a single decision tree for model?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a single decision tree for modeling can lead to several disadvantages:\n",
        "\n",
        "1.Overfitting:\n",
        "\n",
        "  Decision trees are prone to overfitting, especially when the tree is very deep and complex, capturing noise in the data instead of the underlying pattern.\n",
        "\n",
        "2.High Variance:\n",
        "\n",
        "  Small changes in the training data can result in a significantly different tree, leading to instability in predictions.\n",
        "\n",
        "3.Limited Predictive Power:\n",
        "\n",
        "  A single decision tree often lacks the predictive power of ensemble methods (like Random Forests or Gradient Boosting), which combine multiple trees to improve accuracy and robustness.\n",
        "\n",
        "4.Bias-Variance Trade-off:\n",
        "\n",
        "  Decision trees tend to have low bias but very high variance. This can result in poor generalization on unseen data.\n",
        "\n",
        "5.Lack of Smoothness:\n",
        "\n",
        "  Predictions made by a decision tree are stepwise and can lack smooth transitions, which may not align with the continuous nature of some data.\n",
        "\n",
        "6.Difficulty Handling Imbalanced Datasets:\n",
        "\n",
        "  A single decision tree may perform poorly with imbalanced datasets because it doesn't inherently address class imbalance.\n",
        "\n",
        "7.Overdependence on Feature Selection:\n",
        "\n",
        "  Trees can become overly reliant on the most predictive features, ignoring others that might also be important.\n",
        "\n",
        "8.Suboptimal Splits:\n",
        "\n",
        "  Greedy splitting at each node does not guarantee finding the globally optimal tree structure, potentially missing better solutions.\n",
        "\n",
        "9.Not Robust to Outliers:\n",
        "\n",
        "  Decision trees can be significantly impacted by outliers, leading to skewed splits and poor performance.\n",
        "  \n",
        "10.Interpretability Issues in Large Trees:\n",
        "\n",
        "  While small trees are interpretable, larger trees can become complex and difficult to understand.\n",
        "\n",
        "Ensemble methods, like Random Forest or Gradient Boosting, are commonly used to overcome these disadvantages by combining the outputs of multiple trees to produce a more robust and generalized model."
      ],
      "metadata": {
        "id": "pn9FixZg-Yrs"
      },
      "id": "pn9FixZg-Yrs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8222ac9",
      "metadata": {
        "id": "e8222ac9"
      },
      "outputs": [],
      "source": [
        "# Question 2\n",
        "# What is Gini Impurity?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gini Impurity is a metric used in decision trees to measure how \"pure\" a dataset is at a particular node. It quantifies the likelihood of an incorrect classification of a randomly chosen data point if it were labeled according to the distribution of classes at that node.\n",
        "\n",
        "Formula:\n",
        "  The Gini Impurity for a node is calculated as:\n",
        "\n",
        "    G=1‚àí‚àë(i=1,n)Pùëñ^2\n",
        "    ‚Äã\n",
        "    Where:\n",
        "    n: The number of classes.\n",
        "    Pùëñ: The proportion of data points belonging to class\n",
        "    i at the node.\n",
        "\n",
        "Key Characteristics:\n",
        "\n",
        "  Range:Gini Impurity ranges from 0 to just below 1.\n",
        "\n",
        "  ùê∫=0: Perfect purity, where all samples belong to a single class.\n",
        "\n",
        "  ùê∫‚Üí1: Maximum impurity, where samples are evenly distributed across all classes.\n",
        "\n",
        "\n",
        "Purpose:\n",
        "\n",
        "  Gini Impurity is used during the training of a decision tree to decide where to split the data.\n",
        "\n",
        "  A lower Gini Impurity indicates a better split since the resulting subsets are purer.\n",
        "\n",
        "Example:\n",
        "  Consider a node with 100 samples split across two classes:\n",
        "\n",
        "  Class A: 80 samples (ùëùùê¥=0.8)\n",
        "\n",
        "  Class B: 20 samples (ùëùùêµ=0.2)\n",
        "\n",
        "  ùê∫=1‚àí(0.8^2+0.2^2)=1‚àí(0.64+0.04)=0.32\n",
        "\n",
        "This value indicates some impurity, as the node contains samples of both classes.\n",
        "\n",
        "Comparison with Entropy:\n",
        "\n",
        "  Both Gini Impurity and Entropy are used to measure node impurity.\n",
        "\n",
        "  Gini is computationally simpler as it avoids logarithms.\n",
        "\n",
        "  Entropy tends to be more sensitive to class imbalance.\n",
        "\n",
        "In practice, both yield similar results when building decision trees, and the choice between them is often based on preference or computational efficiency."
      ],
      "metadata": {
        "id": "1RttxttFDQnd"
      },
      "id": "1RttxttFDQnd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5622a4",
      "metadata": {
        "id": "5a5622a4"
      },
      "outputs": [],
      "source": [
        "# Question 3\n",
        "# What is data bagging in RF?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Bagging, short for Bootstrap Aggregating, is a key technique used in Random Forests (RF) to improve the performance and robustness of machine learning models. It is a type of ensemble learning method where multiple models are trained on different subsets of the data to reduce variance and enhance generalization.\n",
        "\n",
        "How Data Bagging Works in Random Forests:\n",
        "\n",
        "  1.Bootstrap Sampling:\n",
        "\n",
        "  A dataset with N samples is repeatedly sampled with replacement to create multiple new datasets (called bootstrap samples).\n",
        "\n",
        "  Each bootstrap sample has the same size as the original dataset but may contain duplicate samples.\n",
        "\n",
        "  2.Training Independent Trees:\n",
        "\n",
        "  A decision tree is trained on each bootstrap sample.\n",
        "\n",
        "  This results in a collection of decision trees, each trained on a slightly different subset of the original data.\n",
        "\n",
        "  3.Prediction Aggregation:\n",
        "\n",
        "  For classification tasks: Each tree votes for a class, and the class with the majority votes is chosen (majority voting).\n",
        "\n",
        "  For regression tasks: The predictions of all trees are averaged to get the final prediction.\n",
        "\n",
        "Advantages of Bagging:\n",
        "\n",
        "  1.Reduces Overfitting:\n",
        "\n",
        "  By training on different subsets of the data, it prevents individual trees from overfitting to noise in the dataset.\n",
        "\n",
        "  2.Improves Stability:\n",
        "\n",
        "  Bagging reduces the variance of the model, making it less sensitive to fluctuations in the training data.\n",
        "\n",
        "  3.Handles High Variance Models:\n",
        "\n",
        "  Methods like decision trees, which are prone to overfitting, benefit significantly from bagging.\n",
        "\n",
        "  4.Enhances Robustness:\n",
        "\n",
        "  Combining predictions from multiple models makes the ensemble more robust to outliers and noisy data.\n",
        "\n",
        "Why Bagging is Effective in Random Forests:\n",
        "\n",
        "  Random Forests extend bagging by adding an additional layer of randomness: feature sampling. At each split in a tree, only a random subset of features is considered for splitting.\n",
        "\n",
        "  This ensures that trees are less correlated, further reducing variance and improving overall model performance.\n",
        "\n",
        "  By combining data bagging with feature sampling, Random Forests effectively create a diverse and powerful ensemble of decision trees.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PmaHJoaHOtk9"
      },
      "id": "PmaHJoaHOtk9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22b43745",
      "metadata": {
        "id": "22b43745"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed7a6f33",
      "metadata": {
        "id": "ed7a6f33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9e0a71",
      "metadata": {
        "id": "2e9e0a71"
      },
      "outputs": [],
      "source": [
        "# Question 4\n",
        "# What is feature bagging in RF?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Bagging in Random Forests (RF) is a technique where a random subset of features (columns) is selected for consideration at each split of a decision tree during the training process. This is an additional layer of randomness that helps to reduce the correlation between individual trees in the forest, improving the overall performance of the model.\n",
        "\n",
        "How Feature Bagging Works:\n",
        "\n",
        "  1.Subset of Features:\n",
        "\n",
        "  At each node of a tree, instead of evaluating all the features to find the best split, only a random subset of features is considered.\n",
        "\n",
        "  This subset is selected randomly, and its size is typically smaller than the total number of features.\n",
        "\n",
        "  2.Split Decision:\n",
        "\n",
        "  The best split is determined from the selected subset of features, not from all features.\n",
        "\n",
        "  3.Tree Diversity:\n",
        "\n",
        "  Since different trees will consider different subsets of features at each split, the trees become less correlated and more diverse.\n",
        "\n",
        "Key Parameters for Feature Bagging in RF:\n",
        "\n",
        "For Classification:\n",
        "  Default number of features considered at each split:square root of ùëö‚Äã\n",
        " , where ùëö is the total number of features.\n",
        "\n",
        "For Regression:\n",
        "  Default number of features considered at each split: ùëö/3\n",
        "  , where ùëö  is the total number of features.\n",
        "\n",
        "These defaults can be adjusted using hyperparameters like max_features in many Random Forest implementations.\n",
        "\n",
        "Advantages of Feature Bagging:\n",
        "\n",
        "  1.Reduces Overfitting:\n",
        "\n",
        "  By ensuring that no single feature dominates across all trees, the model becomes less prone to overfitting.\n",
        "\n",
        "  2.Promotes Diversity:\n",
        "\n",
        "  The randomness introduced by feature bagging creates a diverse set of decision trees, enhancing the ensemble's robustness.\n",
        "\n",
        "  3.Improves Generalization:\n",
        "\n",
        "  The ensemble's predictions are more stable and accurate because the trees are less likely to make correlated errors.\n",
        "\n",
        "  4.Handles High-Dimensional Data:\n",
        "\n",
        "  Feature bagging is particularly useful when the dataset has a large number of features, as it reduces computational cost and noise from irrelevant features.\n",
        "\n",
        "Comparison with Data Bagging:\n",
        "\n",
        "    Data Bagging deals with random subsets of data (rows).\n",
        "\n",
        "    Feature Bagging deals with random subsets of features (columns).\n",
        "\n",
        "Why Feature Bagging is Critical in RF:\n",
        "\n",
        "Without feature bagging, decision trees in the Random Forest may all focus on the most predictive features, making them highly correlated. Feature bagging ensures that each tree in the forest explores different patterns in the data, enhancing the ensemble's strength."
      ],
      "metadata": {
        "id": "OgY32nIDUYJX"
      },
      "id": "OgY32nIDUYJX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0c7824",
      "metadata": {
        "id": "0e0c7824"
      },
      "outputs": [],
      "source": [
        "# Question 5\n",
        "# How is the output of RF model claculated using multiple trees in case of a regression model?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Random Forest (RF) regression model, the output is calculated by aggregating the predictions of all the individual decision trees in the forest. The process involves computing the average of the predictions made by the trees.\n",
        "\n",
        "Steps to Calculate the Output:\n",
        "\n",
        "  1.Individual Tree Predictions:\n",
        "\n",
        "  Each decision tree in the Random Forest makes its own prediction for the target variable based on the input features.\n",
        "\n",
        "  Since it‚Äôs a regression model, the prediction from each tree is a continuous numerical value.\n",
        "\n",
        "  2.Aggregation by Averaging:\n",
        "\n",
        "  The predictions from all the trees are collected.\n",
        "\n",
        "  The final output is the mean of these predictions:\n",
        "\n",
        "    ùë¶^=1/ùëá(‚àëùë°=(1,ùëá)ùë¶ùë°)\n",
        "\n",
        "    Where:\n",
        "\n",
        "    ùëá is the total number of trees in the forest.\n",
        "    ùë¶ùë°  is the prediction from the ùë°^ùë°‚Ñé  tree.\n",
        "    ùë¶^  is the final aggregated prediction.\n",
        "    \n",
        "Advantages of Averaging in RF Regression:\n",
        "\n",
        "  1.Reduces Variance:\n",
        "\n",
        "  Averaging the predictions of multiple trees reduces the impact of individual tree variability, leading to more stable and accurate predictions.\n",
        "\n",
        "  2.Handles Overfitting:\n",
        "\n",
        "  While individual trees might overfit, the aggregated result generalizes better to unseen data.\n",
        "\n",
        "  3.Improves Robustness:\n",
        "\n",
        "  Outliers or noise in the training data have less influence on the final prediction due to the averaging process.\n",
        "\n",
        "Key Points:\n",
        "\n",
        "  Unlike Random Forest classification (which uses majority voting), regression uses averaging as the aggregation method.\n",
        "\n",
        "  The diversity of the trees, achieved through data bagging and feature bagging, ensures that the ensemble captures a wide range of patterns, making the final prediction more reliable."
      ],
      "metadata": {
        "id": "ZmAfmTl9bTSX"
      },
      "id": "ZmAfmTl9bTSX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8fd1589",
      "metadata": {
        "id": "a8fd1589"
      },
      "outputs": [],
      "source": [
        "# Question 6\n",
        "# How adaboost improves the result after addition of every weak learner?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost (Adaptive Boosting) improves the model's results after adding each weak learner by focusing more on the data points that were misclassified in the previous iterations. It iteratively adjusts the weights of the training data and combines the predictions of weak learners to create a strong ensemble model.\n",
        "\n",
        "Key Mechanisms in AdaBoost:\n",
        "\n",
        "  1.Weight Adjustment for Data Points:\n",
        "\n",
        "  At the start, all data points are given equal weights.\n",
        "\n",
        "  After training a weak learner (e.g., a decision stump), the algorithm increases the weights of the misclassified data points.\n",
        "\n",
        "  As a result, the next weak learner focuses more on these \"hard-to-classify\" data points.\n",
        "\n",
        "  2.Performance Evaluation of Each Weak Learner:\n",
        "\n",
        "  The performance of each weak learner is evaluated using its weighted error(ùúÄ):\n",
        "              \n",
        "              ùúÄ=‚àëùëñ=(1,ùëÅ)ùë§ùëñ‚ãÖùêº(ùë¶ùëñ‚â†ùë¶^ùëñ)/‚àëùëñ=(1,ùëÅ)ùë§ùëñ\n",
        "\n",
        "\n",
        "      Where:ùë§ùëñ : Weight of the i-th data point.\n",
        "           ùêº(ùë¶ùëñ‚â†ùë¶^ùëñ): Indicator function that equals 1 if the prediction\n",
        "            is incorrect, 0 otherwise.\n",
        "\n",
        "\n",
        "  3.Assigning Importance to Each Weak Learner:\n",
        "\n",
        "Weak learners with lower weighted error are given higher importance (ùõºùë° ):\n",
        "\n",
        "       ùõºùë°=1/2ln(1‚àíùúÄùë°/ùúÄùë°)\n",
        "\n",
        "    A weak learner with high accuracy (low error) has a larger ùõºùë°\n",
        "    , contributing more to the final model's prediction.\n",
        "\n",
        "  3.Update Data Point Weights:\n",
        "\n",
        "  The weights of correctly classified data points are decreased, while the weights of misclassified points are increased:\n",
        "\n",
        "      ùë§ùëñ^(ùë°+1)=ùë§ùëñ^(ùë°)‚ãÖexp(ùõºùë°‚ãÖùêº(ùë¶ùëñ‚â†ùë¶^ùëñ))\n",
        "\n",
        "  This ensures the next weak learner focuses more on the challenging samples.\n",
        "\n",
        "  4.Final Prediction:\n",
        "\n",
        "  The weak learners are combined into a strong learner by weighted voting (for classification) or weighted averaging (for regression):\n",
        "\n",
        "      ùêª(ùë•)=sign(‚àëùë°=(1,ùëá)ùõºùë°‚ãÖ‚Ñéùë°(ùë•))\n",
        "      \n",
        "      Where: ‚Ñéùë°(ùë•): Prediction of the t-th weak learner.\n",
        "      ùõºùë° : Weight (importance) of the t-th weak learner.\n",
        "\n",
        "How Results Improve:\n",
        "\n",
        "  1.Focus on Difficult Cases:\n",
        "  \n",
        "  Misclassified points are prioritized, ensuring that the model improves on harder examples over iterations.\n",
        "\n",
        "  2.Weight Redistribution:\n",
        "\n",
        "  Correctly classified examples have less influence in subsequent rounds, reducing bias and overfitting.\n",
        "\n",
        "  3.Combining Weak Learners:\n",
        "\n",
        "  Weak learners (e.g., simple decision stumps) may perform slightly better than random guessing individually, but their combined output forms a strong model with significantly better accuracy.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Effective in reducing bias and variance.\n",
        "Works well with weak learners as long as they perform slightly better than random chance.\n",
        "\n",
        "Adaptable to both binary and multi-class classification problems.\n",
        "By systematically adjusting weights and combining predictions, AdaBoost turns a sequence of weak models into a robust ensemble that improves with each additional learner.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PTh0XjR_f884"
      },
      "id": "PTh0XjR_f884"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4475e887",
      "metadata": {
        "id": "4475e887"
      },
      "outputs": [],
      "source": [
        "# Questions 7\n",
        "# Which parameter decides the contribution of new weak learner in overall result in case of gradient boosting?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Gradient Boosting, the parameter that decides the contribution of a new weak learner to the overall result is the learning rate (commonly denoted as Œ∑).\n",
        "\n",
        "  Learning Rate (ùúÇ):\n",
        "\n",
        "  The learning rate controls the step size in the direction of the negative gradient, effectively determining how much the new weak learner's predictions impact the overall model.\n",
        "\n",
        "  It is a scalar value between 0 and 1, multiplied by the predictions of the new weak learner before adding them to the ensemble.\n",
        "\n",
        "  Update Rule in Gradient Boosting:\n",
        "\n",
        "  For a regression problem, the prediction after adding the ùë°-th weak learner is updated as:\n",
        "\n",
        "      ùêπùë°(ùë•)=ùêπùë°‚àí1(ùë•)+ùúÇ‚ãÖ‚Ñéùë°(ùë•)\n",
        "\n",
        "      Where:\n",
        "      \n",
        "      ùêπùë°(ùë•): Ensemble prediction after ùë°-th weak learner.\n",
        "\n",
        "      ùêπùë°‚àí1(ùë•): Ensemble prediction after the (ùë°‚àí1)-th weak learner.\n",
        "\n",
        "      ‚Ñéùë°(ùë•): Prediction of the ùë°-th weak learner (fitted to the negative gradient).\n",
        "\n",
        "      ùúÇ: Learning rate.\n",
        "\n",
        "Role of Learning Rate:\n",
        "\n",
        "  1.Controls the Contribution:\n",
        "\n",
        "  A smaller ùúÇ reduces the influence of each weak learner, making the updates more gradual.\n",
        "\n",
        "  A larger ùúÇ increases the impact, leading to faster convergence but with a higher risk of overfitting.\n",
        "\n",
        "  2.Balances Bias-Variance Trade-off:\n",
        "\n",
        "  Lower ùúÇ requires more iterations (more weak learners) but can lead to better generalization.\n",
        "\n",
        "  Higher ùúÇ may reduce training time but risks overfitting if the weak learners are too large or the model is too complex.\n",
        "\n",
        "Tuning Learning Rate:\n",
        "\n",
        "  A typical practice is to set ùúÇ to a small value (e.g., 0.1 or 0.01) and increase the number of weak learners (trees) to ensure a well-performing model.\n",
        "\n",
        "  Grid search or cross-validation can be used to find the optimal ùúÇ for a given dataset.\n",
        "\n",
        "\n",
        "Other Parameters That Influence Contribution:\n",
        "\n",
        "  While the learning rate primarily controls the contribution, other parameters interact with it:\n",
        "\n",
        "  1.Tree Depth:\n",
        "\n",
        "  Deeper trees can fit more complex patterns, increasing the impact of the weak learner.\n",
        "\n",
        "  2.Number of Trees:\n",
        "\n",
        "  More trees can compensate for a smaller learning rate by allowing more iterations to refine the predictions.\n",
        "\n",
        "  3.Subsample:\n",
        "\n",
        "  Fraction of data used for training each weak learner; lower values reduce overfitting and impact the contribution indirectly.\n",
        "\n",
        "By fine-tuning the learning rate and related parameters, Gradient Boosting achieves a balance between model accuracy and generalization.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yyrWiPCQoySu"
      },
      "id": "yyrWiPCQoySu"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uwd0Qad5oxBR"
      },
      "id": "Uwd0Qad5oxBR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2577759d",
      "metadata": {
        "id": "2577759d"
      },
      "outputs": [],
      "source": [
        "# Question 8\n",
        "# How feature importance is calcutaed in xgboost?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In XGBoost, feature importance is calculated to indicate how useful or valuable each feature is for building the decision trees in the model. XGBoost provides several methods to measure feature importance, which are based on how often and effectively features are used in the splits of trees. The common methods include:\n",
        "\n",
        "  1. Gain:\n",
        "\n",
        "  Definition: Gain measures the improvement in accuracy brought by a feature when it is used to split a node.\n",
        "\n",
        "  Calculation:\n",
        "  It is the reduction in the loss function (e.g., Mean Squared Error for regression or Log Loss for classification) achieved by using the feature to split the data at a particular node.\n",
        "\n",
        "  For each feature, the total gain across all splits in all trees is calculated.\n",
        "\n",
        "  Interpretation: Features with higher gain contribute more to reducing the loss function and are considered more important.\n",
        "\n",
        "  2. Frequency (or Weight):\n",
        "\n",
        "  Definition: Frequency counts the number of times a feature is used to split the data across all the trees in the model.\n",
        "\n",
        "  Calculation:\n",
        "\n",
        "  For each feature, count the number of splits where the feature is used.\n",
        "  Normalize the count across all features.\n",
        "\n",
        "  Interpretation: Features with higher frequencies are considered more important.\n",
        "\n",
        "  3. Cover:\n",
        "\n",
        "  Definition: Cover measures the relative number of data samples affected by splits on a feature.\n",
        "\n",
        "  Calculation:\n",
        "\n",
        "  For each feature, sum up the number of data points passing through the nodes where the feature is used.\n",
        "  Normalize the cover value across all features.\n",
        "\n",
        "  Interpretation: Features that affect more samples are considered more important.\n",
        "\n",
        "  4. Total Gain, Total Cover:\n",
        "\n",
        "  Variants of the above metrics aggregate the gain or cover values across all splits and normalize them to calculate importance scores.\n",
        "\n",
        "  How to Retrieve Feature Importance in XGBoost:\n",
        "  Using Python's XGBoost library, you can retrieve feature importance as follows:\n",
        "\n",
        "          from xgboost import XGBClassifier\n",
        "          model = XGBClassifier()\n",
        "          model.fit(X_train, y_train)\n",
        "          # Get feature importance scores\n",
        "         importance = model.get_booster().get_score(importance_type='gain')\n",
        "         # Change to 'weight' or 'cover' if needed\n",
        "\n",
        "  Visualizing Feature Importance:\n",
        "\n",
        "      XGBoost provides a utility for plotting feature importance:\n",
        "\n",
        "            from xgboost import plot_importance\n",
        "            plot_importance(model, importance_type='gain')  # Change to 'weight' or 'cover' if needed\n",
        "\n",
        "Considerations:\n",
        "\n",
        "  Gain is generally considered the most informative metric because it directly relates to how much a feature contributes to model accuracy.\n",
        "\n",
        "  Features with high frequency or cover may not always be the most impactful if their splits contribute little to accuracy.\n",
        "\n",
        "Feature importance can be affected by correlation:\n",
        "  \n",
        "  if two features are highly correlated, their importance may be split between them.\n",
        "\n",
        "  By analyzing feature importance, you can understand which features are driving your model's predictions and use this information for feature selection, model interpretation, or debugging.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FRwRRmgRsH1u"
      },
      "id": "FRwRRmgRsH1u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77b9d9e",
      "metadata": {
        "id": "a77b9d9e"
      },
      "outputs": [],
      "source": [
        "# Question 9\n",
        "# What is the main difference between RF and xgboost model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main differences between Random Forest (RF) and XGBoost lie in their algorithmic approaches, handling of data, and the way they build and combine decision trees. Here's a detailed comparison:\n",
        "\n",
        "  1. Algorithm Type:\n",
        "\n",
        "  Random Forest (RF):\n",
        "\n",
        "  Bagging (Bootstrap Aggregating): RF builds multiple decision trees independently by training them on bootstrap samples (random subsets of data with replacement). The final prediction is based on the average (for regression) or majority vote (for classification) from all trees.\n",
        "\n",
        "  Trees are built in parallel.\n",
        "\n",
        "  XGBoost:\n",
        "\n",
        "  Boosting: XGBoost builds decision trees sequentially. Each new tree corrects the errors of the previous trees by focusing more on misclassified or poorly predicted samples.\n",
        "\n",
        "  Trees are built iteratively.\n",
        "\n",
        "\n",
        "  2. Objective:\n",
        "  \n",
        "  RF:Aims to reduce variance by averaging predictions from many de-correlated trees, which improves generalization and reduces overfitting.\n",
        "\n",
        "  XGBoost:Focuses on reducing both bias and variance by combining weak learners (shallow trees) sequentially and minimizing a specified objective function, typically including a regularization term.\n",
        "\n",
        "\n",
        "  3. Training Strategy:\n",
        "\n",
        "  RF:Trains all trees independently.\n",
        "\n",
        "  Uses a random subset of features at each split (feature bagging), promoting tree diversity.\n",
        "\n",
        "  XGBoost:Trains trees sequentially, with each tree trying to correct the residual errors of the previous trees.\n",
        "\n",
        "  Uses gradient-based optimization to minimize a loss function, such as Mean Squared Error (MSE) for regression or Log Loss for classification.\n",
        "\n",
        "  4. Handling of Data:\n",
        "\n",
        "  RF:Handles missing values implicitly by splitting on features that are available for each sample.\n",
        "\n",
        "  Works well with large datasets without much tuning.\n",
        "\n",
        "  XGBoost:Handles missing values explicitly by learning the best direction (left or right) to handle them during tree construction.\n",
        "\n",
        "  Requires more careful preprocessing and hyperparameter tuning for optimal performance.\n",
        "\n",
        "  5. Regularization:\n",
        "\n",
        "  RF:Implicit regularization through random feature selection and bagging, but no explicit regularization terms.\n",
        "\n",
        "  XGBoost:Includes explicit regularization through L1 (Lasso) and L2 (Ridge) penalties in its objective function, which helps prevent overfitting.\n",
        "\n",
        "  6. Computational Efficiency:\n",
        "\n",
        "  RF:Faster to train as trees are built independently and can be parallelized easily.\n",
        "\n",
        "  XGBoost:Slower to train because trees are built sequentially.\n",
        "\n",
        "  Optimized for computational efficiency with techniques like out-of-core computing for large datasets and pruned trees for faster inference.\n",
        "\n",
        "  7. Interpretability:\n",
        "\n",
        "  RF:Simpler and easier to interpret compared to XGBoost.\n",
        "\n",
        "  Feature importance is based on how frequently and effectively features are used for splits.\n",
        "\n",
        "  XGBoost:More complex due to boosting, but still interpretable via advanced tools like SHAP (SHapley Additive exPlanations) for feature importance analysis.\n",
        "\n",
        "  8. Performance:\n",
        "  \n",
        "  RF:Performs well for many datasets and is robust against overfitting but may struggle to achieve the same accuracy as XGBoost for highly complex datasets.\n",
        "  \n",
        "  XGBoost:Typically outperforms RF on structured/tabular data due to its optimization and regularization, but it requires careful tuning.\n",
        "\n",
        "\n",
        "When to Use:\n",
        "\n",
        "  Random Forest:\n",
        "\n",
        "  Use RF when you need a quick, robust model with minimal tuning.\n",
        "  \n",
        "  Works well on datasets with noisy features or missing values.\n",
        "\n",
        "  XGBoost:\n",
        "\n",
        "  Use XGBoost when high accuracy is critical and you‚Äôre willing to invest time in hyperparameter tuning.\n",
        "\n",
        "\n",
        "  Performs well on large datasets with complex patterns.\n",
        "\n",
        "Summary:\n",
        "\n",
        "  Random Forest relies on bagging and parallel tree construction, making it simpler and faster.\n",
        "  \n",
        "  XGBoost uses boosting, gradient-based optimization, and regularization, making it more accurate for complex datasets but computationally intensive and sensitive to tuning."
      ],
      "metadata": {
        "id": "Holwkh2ozlBZ"
      },
      "id": "Holwkh2ozlBZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08b6885",
      "metadata": {
        "id": "d08b6885"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a54af6",
      "metadata": {
        "id": "39a54af6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f9622f35",
      "metadata": {
        "id": "f9622f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "f97fab9f-bb78-4cc3-fbf2-ce532e4540cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-123adb93-0cfe-4bf6-941a-3d10179cdf4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-123adb93-0cfe-4bf6-941a-3d10179cdf4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-123adb93-0cfe-4bf6-941a-3d10179cdf4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-123adb93-0cfe-4bf6-941a-3d10179cdf4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-32034ff0-d565-4daa-95f4-a8e47eb8ce10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32034ff0-d565-4daa-95f4-a8e47eb8ce10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-32034ff0-d565-4daa-95f4-a8e47eb8ce10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1338,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          21,\n          45,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.098186911679017,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 548,\n        \"samples\": [\n          23.18,\n          26.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"southeast\",\n          \"northeast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12110.011236693994,\n        \"min\": 1121.8739,\n        \"max\": 63770.42801,\n        \"num_unique_values\": 1337,\n        \"samples\": [\n          8688.85885,\n          5708.867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Question 10\n",
        "# Build insurance price prediction model using RF and XGboost. Check which model gives best results.\n",
        "# Dataset insurance.csv included in same folder\n",
        "\n",
        "# Let's first inspect the uploaded file to understand its structure and contents.\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# File path\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/files/insurance.csv'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(file_path)\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('charges', axis=1)\n",
        "y = data['charges']\n",
        "\n",
        "# Handle categorical variables using Label Encoding for simplicity\n",
        "label_encoders = {}\n",
        "categorical_columns = ['sex', 'smoker', 'region']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ocp1v3i23Eri",
        "outputId": "e0cc5906-0aa3-450f-a567-6c440fa5f622"
      },
      "id": "Ocp1v3i23Eri",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age  sex    bmi  children  smoker  region\n",
              "560    46    0  19.95         2       0       1\n",
              "1285   47    0  24.32         0       0       0\n",
              "1142   52    0  24.86         0       0       2\n",
              "969    39    0  34.32         5       0       2\n",
              "486    54    0  21.47         3       0       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdb3e78c-a639-4fd8-a7b2-8a688825f9a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>19.95</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1285</th>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>24.86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>34.32</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>21.47</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdb3e78c-a639-4fd8-a7b2-8a688825f9a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdb3e78c-a639-4fd8-a7b2-8a688825f9a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdb3e78c-a639-4fd8-a7b2-8a688825f9a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8fdeb2f-be41-446e-be42-77f22e6a9cb0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8fdeb2f-be41-446e-be42-77f22e6a9cb0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8fdeb2f-be41-446e-be42-77f22e6a9cb0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train",
              "summary": "{\n  \"name\": \"X_train\",\n  \"rows\": 1070,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          35,\n          33,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.043385672727494,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 494,\n        \"samples\": [\n          27.3,\n          31.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "436b4e9c",
      "metadata": {
        "id": "436b4e9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8629f1d9-9f9b-4f10-d46c-2946b830fe88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21073365.415079337, 0.8642606273649586, 18674935.111475274, 0.87970958002665)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict using Random Forest\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "rf_r2 = r2_score(y_test, rf_predictions)\n",
        "\n",
        "#Reduce the number of estimators for XGBoost to speed up the process 100 to 50\n",
        "xgb_model = xgb.XGBRegressor(random_state=42, n_estimators=50, learning_rate=0.1)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the updated XGBoost model\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate XGBoost\n",
        "xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
        "xgb_r2 = r2_score(y_test, xgb_predictions)\n",
        "\n",
        "rf_mse, rf_r2, xgb_mse, xgb_r2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6f526d0b",
      "metadata": {
        "id": "6f526d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "105f9f88-ce8a-477e-a8c4-3512b8699d4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  Mean Squared Error (MSE)  R^2 Score\n",
              "1        XGBoost              1.867494e+07   0.879710\n",
              "0  Random Forest              2.107337e+07   0.864261"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6d2905e-eb70-4a5f-b6f6-42fbb2792604\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Mean Squared Error (MSE)</th>\n",
              "      <th>R^2 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>1.867494e+07</td>\n",
              "      <td>0.879710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>2.107337e+07</td>\n",
              "      <td>0.864261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6d2905e-eb70-4a5f-b6f6-42fbb2792604')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6d2905e-eb70-4a5f-b6f6-42fbb2792604 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6d2905e-eb70-4a5f-b6f6-42fbb2792604');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9eb9794-8e15-412b-81f8-e82ec4198859\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9eb9794-8e15-412b-81f8-e82ec4198859')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9eb9794-8e15-412b-81f8-e82ec4198859 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"comparison_results\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Random Forest\",\n          \"XGBoost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Squared Error (MSE)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1695946.3318817425,\n        \"min\": 18674935.111475274,\n        \"max\": 21073365.415079337,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          21073365.415079337,\n          18674935.111475274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R^2 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01092405918931198,\n        \"min\": 0.8642606273649586,\n        \"max\": 0.87970958002665,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8642606273649586,\n          0.87970958002665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Comparing the performance of Random Forest and XGBoost\n",
        "\n",
        "# Display the results\n",
        "comparison_results = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"XGBoost\"],\n",
        "    \"Mean Squared Error (MSE)\": [rf_mse, xgb_mse],\n",
        "    \"R^2 Score\": [rf_r2, xgb_r2]\n",
        "})\n",
        "\n",
        "comparison_results.sort_values(\"R^2 Score\", ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6dd58949",
      "metadata": {
        "id": "6dd58949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582e7662-9e38-4e0e-c2cf-bae15e74586d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison Results:\n",
            "           Model  Root Mean Squared Error (RMSE)  \\\n",
            "0  Random Forest                     4590.573539   \n",
            "1        XGBoost                     4321.450580   \n",
            "\n",
            "   Median Absolute Error (MedAE)  Mean Squared Error (MSE)  R^2 Score  \n",
            "0                    1100.029987              2.107337e+07   0.864261  \n",
            "1                    1306.058640              1.867494e+07   0.879710  \n",
            "\n",
            "Best Model Based on RMSE:\n",
            "Model                                     XGBoost\n",
            "Root Mean Squared Error (RMSE)         4321.45058\n",
            "Median Absolute Error (MedAE)          1306.05864\n",
            "Mean Squared Error (MSE)          18674935.111475\n",
            "R^2 Score                                 0.87971\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import median_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate evaluation metrics for Random Forest\n",
        "rf_rmse = np.sqrt(rf_mse)\n",
        "rf_medae = median_absolute_error(y_test, rf_predictions)\n",
        "\n",
        "# Calculate evaluation metrics for XGBoost\n",
        "xgb_rmse = np.sqrt(xgb_mse)\n",
        "xgb_medae = median_absolute_error(y_test, xgb_predictions)\n",
        "\n",
        "# Compare the metrics\n",
        "comparison_results = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"XGBoost\"],\n",
        "    \"Root Mean Squared Error (RMSE)\": [rf_rmse, xgb_rmse],\n",
        "    \"Median Absolute Error (MedAE)\": [rf_medae, xgb_medae],\n",
        "    \"Mean Squared Error (MSE)\": [rf_mse, xgb_mse],\n",
        "    \"R^2 Score\": [rf_r2, xgb_r2]\n",
        "})\n",
        "\n",
        "# Determine the winner based on the lowest RMSE\n",
        "winner = comparison_results.loc[comparison_results[\"Root Mean Squared Error (RMSE)\"].idxmin()]\n",
        "\n",
        "print(\"Comparison Results:\")\n",
        "print(comparison_results)\n",
        "print(\"\\nBest Model Based on RMSE:\")\n",
        "print(winner)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "994e4026",
      "metadata": {
        "id": "994e4026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "eadbfdd1-13dc-4720-c29f-cdf3bdf81761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison Results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a8e2c80f370>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_58015 th {\n",
              "  font-size: 12pt;\n",
              "  text-align: center;\n",
              "  background-color: #f2f2f2;\n",
              "}\n",
              "#T_58015 td {\n",
              "  font-size: 12pt;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_58015_row0_col2, #T_58015_row1_col1, #T_58015_row1_col3 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "#T_58015_row1_col4 {\n",
              "  background-color: lightblue;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_58015\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_58015_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_58015_level0_col1\" class=\"col_heading level0 col1\" >Root Mean Squared Error (RMSE)</th>\n",
              "      <th id=\"T_58015_level0_col2\" class=\"col_heading level0 col2\" >Median Absolute Error (MedAE)</th>\n",
              "      <th id=\"T_58015_level0_col3\" class=\"col_heading level0 col3\" >Mean Squared Error (MSE)</th>\n",
              "      <th id=\"T_58015_level0_col4\" class=\"col_heading level0 col4\" >R^2 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_58015_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_58015_row0_col0\" class=\"data row0 col0\" >Random Forest</td>\n",
              "      <td id=\"T_58015_row0_col1\" class=\"data row0 col1\" >4590.573539</td>\n",
              "      <td id=\"T_58015_row0_col2\" class=\"data row0 col2\" >1100.029987</td>\n",
              "      <td id=\"T_58015_row0_col3\" class=\"data row0 col3\" >21073365.415079</td>\n",
              "      <td id=\"T_58015_row0_col4\" class=\"data row0 col4\" >0.864261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_58015_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_58015_row1_col0\" class=\"data row1 col0\" >XGBoost</td>\n",
              "      <td id=\"T_58015_row1_col1\" class=\"data row1 col1\" >4321.450580</td>\n",
              "      <td id=\"T_58015_row1_col2\" class=\"data row1 col2\" >1306.058640</td>\n",
              "      <td id=\"T_58015_row1_col3\" class=\"data row1 col3\" >18674935.111475</td>\n",
              "      <td id=\"T_58015_row1_col4\" class=\"data row1 col4\" >0.879710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model Based on RMSE:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model                                     XGBoost\n",
              "Root Mean Squared Error (RMSE)         4321.45058\n",
              "Median Absolute Error (MedAE)          1306.05864\n",
              "Mean Squared Error (MSE)          18674935.111475\n",
              "R^2 Score                                 0.87971\n",
              "Name: 1, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <td>XGBoost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Root Mean Squared Error (RMSE)</th>\n",
              "      <td>4321.45058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median Absolute Error (MedAE)</th>\n",
              "      <td>1306.05864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean Squared Error (MSE)</th>\n",
              "      <td>18674935.111475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R^2 Score</th>\n",
              "      <td>0.87971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Enhanced table layout for displaying comparison results\n",
        "comparison_results = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"XGBoost\"],\n",
        "    \"Root Mean Squared Error (RMSE)\": [rf_rmse, xgb_rmse],\n",
        "    \"Median Absolute Error (MedAE)\": [rf_medae, xgb_medae],\n",
        "    \"Mean Squared Error (MSE)\": [rf_mse, xgb_mse],\n",
        "    \"R^2 Score\": [rf_r2, xgb_r2]\n",
        "}).style.set_table_styles([\n",
        "    {'selector': 'th', 'props': [('font-size', '12pt'), ('text-align', 'center'), ('background-color', '#f2f2f2')]},\n",
        "    {'selector': 'td', 'props': [('font-size', '12pt'), ('text-align', 'center')]}\n",
        "]).highlight_min(subset=[\"Root Mean Squared Error (RMSE)\", \"Median Absolute Error (MedAE)\", \"Mean Squared Error (MSE)\"], color='lightgreen', axis=0).highlight_max(subset=[\"R^2 Score\"], color='lightblue', axis=0)\n",
        "\n",
        "# Winner based on RMSE\n",
        "winner = comparison_results.data.loc[comparison_results.data[\"Root Mean Squared Error (RMSE)\"].idxmin()]\n",
        "\n",
        "print(\"Comparison Results:\")\n",
        "display(comparison_results)\n",
        "\n",
        "print(\"\\nBest Model Based on RMSE:\")\n",
        "display(winner)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183a44b6",
      "metadata": {
        "id": "183a44b6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf4ee45",
      "metadata": {
        "id": "aaf4ee45"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5303135",
      "metadata": {
        "id": "d5303135"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42798e80",
      "metadata": {
        "id": "42798e80"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8714b9e6",
      "metadata": {
        "id": "8714b9e6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73474fb2",
      "metadata": {
        "id": "73474fb2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}